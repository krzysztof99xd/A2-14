{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Assignment 2, Natural Language Processing, Group 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset and choose only the articles where NVIDIA word appears in the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id ticker                                              title  \\\n",
      "24      221539    NIO  A Central Bank War Just Started And Its Good F...   \n",
      "32      221547    NIO         6 Stocks To Watch  Nivida Could Be Falling   \n",
      "57      221572    NIO  Stocks   Dow Drops Nearly 400 Points as Apple ...   \n",
      "78      221593   UBER  The Zacks Analyst Blog Highlights  Advanced Mi...   \n",
      "82      221597   UBER                     The Best Of CES 2020  Revised    \n",
      "...        ...    ...                                                ...   \n",
      "221141  442657    AMD    Here s Why Nvidia  NVDA  Stock Is Gaining Today   \n",
      "221166  442682    AMD      4 Stocks To Watch Today  ATW  CWEI  MXL  SLCA   \n",
      "221189  442705    AMD  Here s What The Buy Side Expects From AMD Thur...   \n",
      "221468  442984      T  Zacks com Featured Highlights  AT T  Nu Skin E...   \n",
      "221471  442987      T  5 Dividend Growth Stocks To Sail Through Uncer...   \n",
      "\n",
      "       category                                            content  \\\n",
      "24      opinion  ECB Effects\\nThe move in the euro was huge  fa...   \n",
      "32      opinion  6 Stocks To Watch  March 6 Trading Session\\nSt...   \n",
      "57         news  Investing com   A rout in Apple and Facebook  ...   \n",
      "78      opinion  For Immediate ReleaseChicago  IL   January 13 ...   \n",
      "82      opinion  With 4 500 companies bringing their innovation...   \n",
      "...         ...                                                ...   \n",
      "221141  opinion  Shares of Nvidia   NASDAQ NVDA   are up nearly...   \n",
      "221166  opinion  It was a pretty good start to the week on Mond...   \n",
      "221189  opinion  Advanced Micro Devices Inc   NYSE AMD  is set ...   \n",
      "221468  opinion  For Immediate Release\\n\\nChicago  IL   July 22...   \n",
      "221471  opinion  With uncertainty ruling the markets since the ...   \n",
      "\n",
      "       release_date                   provider  \\\n",
      "24       2019-03-07             Michael Kramer   \n",
      "32       2019-03-06             Michael Kramer   \n",
      "57       2018-11-19              Investing.com   \n",
      "78       2020-01-12  Zacks Investment Research   \n",
      "82       2020-01-16  Zacks Investment Research   \n",
      "...             ...                        ...   \n",
      "221141   2016-09-27  Zacks Investment Research   \n",
      "221166   2016-05-17                Harry Boxer   \n",
      "221189   2014-04-17                   Estimize   \n",
      "221468   2016-07-21  Zacks Investment Research   \n",
      "221471   2016-07-20  Zacks Investment Research   \n",
      "\n",
      "                                                      url  article_id  \n",
      "24      https://www.investing.com/analysis/a-central-b...   200395687  \n",
      "32      https://www.investing.com/analysis/6-stocks-to...   200394931  \n",
      "57      https://www.investing.com/news/stock-market-ne...     1694042  \n",
      "78      https://www.investing.com/analysis/the-zacks-a...   200498277  \n",
      "82      https://www.investing.com/analysis/the-best-of...   200499164  \n",
      "...                                                   ...         ...  \n",
      "221141  https://www.investing.com/analysis/here's-why-...   200155860  \n",
      "221166  https://www.investing.com/analysis/atw,-cwei,-...   200130262  \n",
      "221189  https://www.investing.com/analysis/hereâ€™s-what...      209915  \n",
      "221468  https://www.investing.com/analysis/zacks.com-f...   200143537  \n",
      "221471  https://www.investing.com/analysis/5-dividend-...   200143306  \n",
      "\n",
      "[3400 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('us_equities_news_dataset.csv')\n",
    "\n",
    "# Filter rows where 'content' column contains the word 'NVIDIA'\n",
    "nvidia_rows = df[df['content'].str.contains('NVIDIA', case=False, na=False)]\n",
    "\n",
    "# Display the filtered rows\n",
    "print(nvidia_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'ticker', 'title', 'category', 'content', 'release_date',\n",
      "       'provider', 'url', 'article_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Remove the specified columns\n",
    "nvidia_rows = nvidia_rows.drop(['id', 'ticker', 'url', 'release_date'], axis=1)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "nvidia_rows.to_csv('nvidia_rows_news_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Sample of preprocessed content:\n",
      "                                             content  \\\n",
      "0  ECB Effects\\nThe move in the euro was huge  fa...   \n",
      "1  6 Stocks To Watch  March 6 Trading Session\\nSt...   \n",
      "2  Investing com   A rout in Apple and Facebook  ...   \n",
      "3  For Immediate ReleaseChicago  IL   January 13 ...   \n",
      "4  With 4 500 companies bringing their innovation...   \n",
      "\n",
      "                                preprocessed_content  \n",
      "0  [ecb, effect, move, euro, huge, fall, pip, hug...  \n",
      "1  [stock, watch, march, trade, session, stock, s...  \n",
      "2  [invest, com, rout, appl, facebook, nasdaq, mo...  \n",
      "3  [immedi, releasechicago, januari, zack, com, a...  \n",
      "4  [compani, bring, innov, ce, jan, get, realli, ...  \n",
      "Length of text_data 100\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(texts):\n",
    "    n=0\n",
    "    processed_texts = []\n",
    "    # lowercasing, keep text only, remove accents, tokenization\n",
    "    tokens = [word for word in word_tokenize(re.sub(r'[^a-zA-Z\\s]', '', unidecode(texts.lower())))]\n",
    "    # stopword removal\n",
    "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "    # remove short words\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "        \n",
    "    # Apply stemming to each token\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "    processed_texts.append(stemmed_tokens)\n",
    "\n",
    "    # remove top-n% and bottom-n% words (optional)\n",
    "    if n > 0:\n",
    "        word_freq = Counter([word for sentence in processed_texts for word in sentence])\n",
    "        top_n = set([word for word, _ in word_freq.most_common(int(n/100*len(word_freq)))])\n",
    "        bottom_n = set([word for word, _ in word_freq.most_common()[:-int(n/100*len(word_freq))-1:-1]])\n",
    "        processed_texts = [[word for word in sentence if word not in top_n and word not in bottom_n] for sentence in processed_texts] \n",
    "\n",
    "    # Flattening the list of lists into a single list\n",
    "    flattened_list = [item for sublist in processed_texts for item in sublist]\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "# Example usage\n",
    "FILE_PATH = 'nvidia_rows_news_dataset.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "# df = df.head(100)\n",
    "text_data = df['content'].tolist()\n",
    "\n",
    "# Apply preprocessing function to each article and create a new column 'preprocessed_content'\n",
    "df['preprocessed_content'] = df['content'].apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing complete. Sample of preprocessed content:\")\n",
    "print(df[['content', 'preprocessed_content']].head())  # Display a sample\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('nvidia_rows_news_dataset_preprocessed.csv', index=False)\n",
    "\n",
    "print(f\"Length of text_data {len(text_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [ecb, effect, move, euro, huge, fall, pip, hug...\n",
      "1    [stock, watch, march, trade, session, stock, s...\n",
      "Name: preprocessed_content, dtype: object\n",
      "(0, '0.014*\"billion\" + 0.013*\"invest\" + 0.010*\"firm\" + 0.009*\"also\" + 0.007*\"new\"')\n",
      "(1, '0.021*\"nasdaq\" + 0.013*\"nyse\" + 0.012*\"stock\" + 0.010*\"trade\" + 0.010*\"inc\"')\n",
      "(2, '0.000*\"compani\" + 0.000*\"stock\" + 0.000*\"market\" + 0.000*\"fund\" + 0.000*\"nasdaq\"')\n",
      "(3, '0.001*\"compani\" + 0.001*\"market\" + 0.001*\"year\" + 0.000*\"nasdaq\" + 0.000*\"drive\"')\n",
      "(4, '0.001*\"nasdaq\" + 0.001*\"compani\" + 0.001*\"inc\" + 0.001*\"stock\" + 0.001*\"billion\"')\n",
      "(5, '0.022*\"nasdaq\" + 0.015*\"inc\" + 0.012*\"stock\" + 0.010*\"nyse\" + 0.009*\"day\"')\n",
      "(6, '0.018*\"year\" + 0.017*\"stock\" + 0.015*\"zack\" + 0.014*\"compani\" + 0.011*\"rate\"')\n",
      "(7, '0.014*\"drive\" + 0.010*\"vehicl\" + 0.009*\"compani\" + 0.009*\"self\" + 0.009*\"market\"')\n",
      "(8, '0.017*\"zack\" + 0.016*\"compani\" + 0.014*\"year\" + 0.014*\"nasdaq\" + 0.012*\"earn\"')\n",
      "(9, '0.033*\"fund\" + 0.029*\"softbank\" + 0.020*\"vision\" + 0.013*\"invest\" + 0.010*\"billion\"')\n",
      "(10, '0.042*\"nasdaq\" + 0.026*\"nyse\" + 0.021*\"inc\" + 0.016*\"close\" + 0.015*\"rose\"')\n",
      "(11, '0.014*\"amazon\" + 0.011*\"year\" + 0.011*\"compani\" + 0.009*\"drive\" + 0.008*\"servic\"')\n",
      "(12, '0.001*\"nasdaq\" + 0.001*\"compani\" + 0.001*\"year\" + 0.000*\"nyse\" + 0.000*\"stock\"')\n",
      "(13, '0.024*\"aurora\" + 0.020*\"compani\" + 0.019*\"drive\" + 0.013*\"vehicl\" + 0.013*\"self\"')\n",
      "(14, '0.009*\"year\" + 0.009*\"nasdaq\" + 0.009*\"stock\" + 0.008*\"investor\" + 0.008*\"tesla\"')\n",
      "0.38942047636500643\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import re\n",
    "\n",
    "read_processed_data = df['preprocessed_content']\n",
    "# Create a dictionary and corpus from the preprocessed data\n",
    "dictionary = corpora.Dictionary(read_processed_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in read_processed_data]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=15, random_state=100, passes=10)\n",
    "\n",
    "# Print the topics found by the LDA model\n",
    "topics = lda_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)\n",
    "#Get coherence score\n",
    "print(CoherenceModel(model=lda_model, texts=read_processed_data, dictionary=dictionary, coherence='c_v').get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  BERTTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bert Topic code\n",
    "# Convert the 'preprocessed_content' column to a list of documents (text format)\n",
    "documents = [\" \".join(tokens) for tokens in df['preprocessed_content']]\n",
    "\n",
    "# Initialize BERTopic model\n",
    "topic_model = BERTopic()\n",
    "\n",
    "# Fit the model on the documents to get topics and probabilities\n",
    "topics, probabilities = topic_model.fit_transform(documents)\n",
    "\n",
    "# Show a summary of topics\n",
    "print(topic_model.get_topic_info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check certain topic\n",
    "num_topic = 0\n",
    "topic_model.get_topic(num_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "topic_model.visualize_heatmap(width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLSA-W Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FLSA-W Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
